{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Models\n",
    "Data: http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'data/spa-eng/spa.txt'\n",
    "with open(txt) as f:\n",
    "    lines = f.read().split('\\n')[:-1]\n",
    "\n",
    "textPairs = []\n",
    "for line in lines:\n",
    "    english, spanish = line.split('\\t')\n",
    "    spanish = '[start] ' + spanish + ' [end]'\n",
    "    textPairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(textPairs)\n",
    "numValSamp = int(0.15 * len(textPairs))\n",
    "numTrainSamp = len(textPairs) - 2 * numValSamp\n",
    "trainPairs = textPairs[:numTrainSamp]\n",
    "valPairs = textPairs[numTrainSamp: numTrainSamp + numValSamp]\n",
    "testPairs = textPairs[numTrainSamp + numValSamp:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 22:51:10.422167: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 22:51:10.575082: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-29 22:51:11.156008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lkeon/anaconda3/envs/tfenv/lib/:/home/lkeon/anaconda3/envs/tfenv/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-06-29 22:51:11.156061: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/lkeon/anaconda3/envs/tfenv/lib/:/home/lkeon/anaconda3/envs/tfenv/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-06-29 22:51:11.156067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-06-29 22:51:11.645145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-29 22:51:11.688135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-29 22:51:11.688284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-29 22:51:11.688650: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-29 22:51:11.689941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-29 22:51:11.690050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-29 22:51:11.690134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-29 22:51:12.111724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-29 22:51:12.111873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-29 22:51:12.111977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-29 22:51:12.112065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9398 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:08:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "stripChars = string.punctuation + '¿'\n",
    "stripChars = stripChars.replace('[', '')\n",
    "stripChars = stripChars.replace(']', '')\n",
    "\n",
    "def custom_text_filter(stringIn):\n",
    "    lowercase = tf.strings.lower(stringIn)\n",
    "    return tf.strings.regex_replace(lowercase, f'[{re.escape(stripChars)}]', '')\n",
    "\n",
    "vocabSize = 15000\n",
    "sequenceLen = 20\n",
    "\n",
    "sourceVectorisation = layers.TextVectorization(\n",
    "    max_tokens=vocabSize,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequenceLen,\n",
    ")\n",
    "targetVectorisation = layers.TextVectorization(\n",
    "    max_tokens=vocabSize,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequenceLen + 1,\n",
    "    standardize=custom_text_filter,\n",
    ")\n",
    "trainEnglishTexts = [pair[0] for pair in trainPairs]\n",
    "trainSpanishTexts = [pair[1] for pair in trainPairs]\n",
    "sourceVectorisation.adapt(trainEnglishTexts)\n",
    "targetVectorisation.adapt(trainSpanishTexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected!\n"
     ]
    }
   ],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print('GPU detected!')\n",
    "else:\n",
    "    print('GPU not detected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training data\n",
    "batchSize = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = sourceVectorisation(eng)\n",
    "    spa = targetVectorisation(spa)\n",
    "    return (\n",
    "        {'english': eng, 'spanish': spa[:, :-1]},\n",
    "        spa[:, 1:])  # target Spanish sequence is one step ahead\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    engTexts, spaTexts = zip(*pairs)\n",
    "    engTexts = list(engTexts)\n",
    "    spaTexts = list(spaTexts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((engTexts, spaTexts))\n",
    "    dataset = dataset.batch(batchSize)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=6)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "trainDs = make_dataset(trainPairs)\n",
    "valDs = make_dataset(valPairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input English shape: (64, 20)\n",
      "input Spanish shape: (64, 20)\n",
      "targets Spanish shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 22:51:28.815039: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# check database structure\n",
    "for inputs, targets in trainDs.take(1):\n",
    "    print('input English shape: {}'.format(inputs['english'].shape))\n",
    "    print('input Spanish shape: {}'.format(inputs['spanish'].shape))\n",
    "    print('targets Spanish shape: {}'.format(targets.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence to Sequence Using RNN\n",
    "RNN were dominant seq to seq models from 2015 to 2017, then overtaken by transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "\n",
    "source = keras.Input(shape=(None,), dtype='int64', name='english')\n",
    "x = layers.Embedding(vocabSize, embed_dim, mask_zero=True)(source)\n",
    "encoded_source = layers.Bidirectional(layers.GRU(latent_dim), merge_mode='sum')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_target = keras.Input(shape=(None,), dtype='int64', name='spanish')\n",
    "x = layers.Embedding(vocabSize, embed_dim, mask_zero=True)(past_target)\n",
    "\n",
    "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
    "x = decoder_gru(x, initial_state=encoded_source)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "target_next_step = layers.Dense(vocabSize, activation='softmax')(x)  # predict next token\n",
    "seq2seq_rnn = keras.Model([source, past_target], target_next_step)\n",
    "\n",
    "# RNN loks token from 0 to N to predict next token, which is shifted by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " english (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " spanish (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 256)    3840000     ['english[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 256)    3840000     ['spanish[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 2048)         28336128    ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                    (None, None, 2048)   14168064    ['embedding_1[0][0]',            \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 2048)   0           ['gru_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 15000)  30735000    ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 80,919,192\n",
      "Trainable params: 80,919,192\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 22:51:41.040479: W tensorflow/core/common_runtime/forward_type_inference.cc:332] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_41/output/_22'\n",
      "2023-06-29 22:51:41.834169: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2023-06-29 22:51:42.015943: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - 137s 100ms/step - loss: 1.5768 - accuracy: 0.4364 - val_loss: 1.2629 - val_accuracy: 0.5264\n",
      "Epoch 2/30\n",
      "1302/1302 [==============================] - 128s 98ms/step - loss: 1.2372 - accuracy: 0.5512 - val_loss: 1.1038 - val_accuracy: 0.5868\n",
      "Epoch 3/30\n",
      "1302/1302 [==============================] - 127s 98ms/step - loss: 1.0920 - accuracy: 0.6011 - val_loss: 1.0337 - val_accuracy: 0.6155\n",
      "Epoch 4/30\n",
      "1302/1302 [==============================] - 129s 99ms/step - loss: 1.0065 - accuracy: 0.6332 - val_loss: 1.0062 - val_accuracy: 0.6308\n",
      "Epoch 5/30\n",
      "1302/1302 [==============================] - 128s 98ms/step - loss: 0.9614 - accuracy: 0.6563 - val_loss: 1.0002 - val_accuracy: 0.6367\n",
      "Epoch 6/30\n",
      "1302/1302 [==============================] - 132s 101ms/step - loss: 0.9368 - accuracy: 0.6718 - val_loss: 0.9998 - val_accuracy: 0.6427\n",
      "Epoch 7/30\n",
      "1302/1302 [==============================] - 135s 103ms/step - loss: 0.9234 - accuracy: 0.6825 - val_loss: 1.0038 - val_accuracy: 0.6423\n",
      "Epoch 8/30\n",
      "1302/1302 [==============================] - 134s 103ms/step - loss: 0.9172 - accuracy: 0.6885 - val_loss: 1.0066 - val_accuracy: 0.6427\n",
      "Epoch 9/30\n",
      "1302/1302 [==============================] - 134s 103ms/step - loss: 0.9155 - accuracy: 0.6919 - val_loss: 1.0102 - val_accuracy: 0.6433\n",
      "Epoch 10/30\n",
      "1302/1302 [==============================] - 133s 102ms/step - loss: 0.9158 - accuracy: 0.6934 - val_loss: 1.0155 - val_accuracy: 0.6436\n",
      "Epoch 11/30\n",
      "1302/1302 [==============================] - 133s 102ms/step - loss: 0.9195 - accuracy: 0.6935 - val_loss: 1.0205 - val_accuracy: 0.6432\n",
      "Epoch 12/30\n",
      "1302/1302 [==============================] - 133s 102ms/step - loss: 0.9256 - accuracy: 0.6910 - val_loss: 1.0225 - val_accuracy: 0.6422\n",
      "Epoch 13/30\n",
      "1302/1302 [==============================] - 133s 102ms/step - loss: 0.9343 - accuracy: 0.6882 - val_loss: 1.0292 - val_accuracy: 0.6399\n",
      "Epoch 14/30\n",
      "1302/1302 [==============================] - 131s 101ms/step - loss: 0.9438 - accuracy: 0.6841 - val_loss: 1.0358 - val_accuracy: 0.6374\n",
      "Epoch 15/30\n",
      "1302/1302 [==============================] - 131s 100ms/step - loss: 0.9558 - accuracy: 0.6799 - val_loss: 1.0387 - val_accuracy: 0.6360\n",
      "Epoch 16/30\n",
      "1302/1302 [==============================] - 131s 101ms/step - loss: 0.9680 - accuracy: 0.6742 - val_loss: 1.0418 - val_accuracy: 0.6356\n",
      "Epoch 17/30\n",
      "1302/1302 [==============================] - 131s 101ms/step - loss: 0.9811 - accuracy: 0.6692 - val_loss: 1.0500 - val_accuracy: 0.6324\n",
      "Epoch 18/30\n",
      "1302/1302 [==============================] - 131s 101ms/step - loss: 0.9951 - accuracy: 0.6631 - val_loss: 1.0549 - val_accuracy: 0.6306\n",
      "Epoch 19/30\n",
      "1302/1302 [==============================] - 131s 101ms/step - loss: 1.0107 - accuracy: 0.6572 - val_loss: 1.0612 - val_accuracy: 0.6286\n",
      "Epoch 20/30\n",
      "1302/1302 [==============================] - 131s 101ms/step - loss: 1.0243 - accuracy: 0.6514 - val_loss: 1.0674 - val_accuracy: 0.6258\n",
      "Epoch 21/30\n",
      "1302/1302 [==============================] - 131s 101ms/step - loss: 1.0406 - accuracy: 0.6453 - val_loss: 1.0757 - val_accuracy: 0.6227\n",
      "Epoch 22/30\n",
      "1302/1302 [==============================] - 130s 100ms/step - loss: 1.0566 - accuracy: 0.6387 - val_loss: 1.0855 - val_accuracy: 0.6168\n",
      "Epoch 23/30\n",
      "1302/1302 [==============================] - 130s 100ms/step - loss: 1.0745 - accuracy: 0.6319 - val_loss: 1.0917 - val_accuracy: 0.6151\n",
      "Epoch 24/30\n",
      "1302/1302 [==============================] - 130s 100ms/step - loss: 1.0878 - accuracy: 0.6263 - val_loss: 1.0993 - val_accuracy: 0.6115\n",
      "Epoch 25/30\n",
      "1302/1302 [==============================] - 130s 100ms/step - loss: 1.1066 - accuracy: 0.6198 - val_loss: 1.1131 - val_accuracy: 0.6055\n",
      "Epoch 26/30\n",
      "1302/1302 [==============================] - 130s 100ms/step - loss: 1.1226 - accuracy: 0.6132 - val_loss: 1.1201 - val_accuracy: 0.6026\n",
      "Epoch 27/30\n",
      "1302/1302 [==============================] - 130s 100ms/step - loss: 1.1403 - accuracy: 0.6065 - val_loss: 1.1337 - val_accuracy: 0.5974\n",
      "Epoch 28/30\n",
      "1302/1302 [==============================] - 132s 101ms/step - loss: 1.1573 - accuracy: 0.5995 - val_loss: 1.1429 - val_accuracy: 0.5933\n",
      "Epoch 29/30\n",
      "1302/1302 [==============================] - 132s 102ms/step - loss: 1.1717 - accuracy: 0.5943 - val_loss: 1.1525 - val_accuracy: 0.5906\n",
      "Epoch 30/30\n",
      "1302/1302 [==============================] - 132s 102ms/step - loss: 1.1895 - accuracy: 0.5875 - val_loss: 1.1666 - val_accuracy: 0.5850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5902f6d70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_rnn.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "seq2seq_rnn.fit(trainDs, epochs=30, validation_data=valDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "It's an inside joke.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] es un poco de la [UNK] [end]\n",
      "-\n",
      "That desk does not fit in this room.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "[start] esa no en esta ciudad [end]\n",
      "-\n",
      "The wound is healing.\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] la [UNK] está [UNK] [end]\n",
      "-\n",
      "I have been studying English for five years.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[start] yo he estado estudiando inglés por tres años [end]\n",
      "-\n",
      "A heavy rain began to fall.\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] un gran de le dejó de nuevo [end]\n",
      "-\n",
      "Tom will already be asleep when we arrive.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[start] tom ya se puede cuando [UNK] cuando [end]\n",
      "-\n",
      "He raised his hat when he saw me.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[start] Él la sombrero me dio su nombre [end]\n",
      "-\n",
      "The only thing Tom needs now is a little patience.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[start] el único que tom necesita que mary no se puede hacer una cosa [end]\n",
      "-\n",
      "I was trying to talk to you.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] te estaba esperando a hablar contigo [end]\n",
      "-\n",
      "I heard my name called.\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] he oído mi nombre de al lado [end]\n",
      "-\n",
      "Is there any reason for that?\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] hay alguna razón para hacerlo [end]\n",
      "-\n",
      "Tom can't eat peanuts.\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[start] tom no puede comer [end]\n",
      "-\n",
      "There must be a rational explanation for this.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[start] debe haber una haber [UNK] [end]\n",
      "-\n",
      "What else could I have done?\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] qué más podría haber hecho [end]\n",
      "-\n",
      "I have a terrible pain.\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] tengo un dolor de cabeza [end]\n",
      "-\n",
      "We'll teach you how to read.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] te leer leer [end]\n",
      "-\n",
      "She needs our help.\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] ella necesita nuestra ayuda [end]\n",
      "-\n",
      "What did you want to tell me?\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "[start] qué quieres decir [end]\n",
      "-\n",
      "I don't believe you. You're always telling lies.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[start] no creo que te [UNK] con usted [end]\n",
      "-\n",
      "He told me that you were right.\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "[start] Él me dijo que lo haga [end]\n"
     ]
    }
   ],
   "source": [
    "# predictions - sampling from the model\n",
    "import numpy as np\n",
    "spaVocab = targetVectorisation.get_vocabulary()\n",
    "spaIndexLookup = dict(zip(range(len(spaVocab)), spaVocab))\n",
    "maxDecodedSentenceLen = 20\n",
    "\n",
    "def decode_sequence(inputSeq):\n",
    "    tokenizedInputSeq = sourceVectorisation([inputSeq])\n",
    "    decodedSentence = '[start]'\n",
    "    for i in range(maxDecodedSentenceLen):\n",
    "        tokenizedTargetSeq = targetVectorisation([decodedSentence])\n",
    "        nextTokenPredictions = seq2seq_rnn.predict(\n",
    "            [tokenizedInputSeq, tokenizedTargetSeq])\n",
    "        sampledTokenIndex = np.argmax(nextTokenPredictions[0, i, :])\n",
    "        sampledToken = spaIndexLookup[sampledTokenIndex]\n",
    "        decodedSentence += ' ' + sampledToken\n",
    "        if sampledToken == '[end]':\n",
    "            break\n",
    "    return decodedSentence\n",
    "\n",
    "testEngTest = [pair[0] for pair in testPairs]\n",
    "for _ in range(20):\n",
    "    inputSeq = random.choice(testEngTest)\n",
    "    print('-')\n",
    "    print(inputSeq)\n",
    "    print(decode_sequence(inputSeq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erthenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
